\section{Introduction}
\begin{multicols}{2}
\noindent
Recent advances in medical image segmentation have been propelled by the synergy of UNet-based architectures \cite{zhou2020unet++, huang2021unet3+} and diffusion models \cite{liu2024biomedical, shi2025diffusion}. While traditional CNNs like UNet++ \cite{zhou2020unet++} addressed feature hierarchy limitations through nested skip connections, subsequent innovations such as UNet 3+ \cite{huang2021unet3+} expanded this framework with full-scale aggregation. These architectures laid critical foundations for handling anatomical complexity but faced persistent challenges in modeling ambiguity \cite{rahman2023ambiguous} and 3D consistency \cite{hu2024diffunet}.
The advent of diffusion models has introduced paradigm-shifting approaches for uncertainty quantification. Concurrently, hybrid frameworks like MedSegDiff \cite{wu2023medsegdiff} and its transformer-enhanced variant \cite{wu2023medsegdiffv2} integrate diffusion steps directly into segmentation pipelines, achieving state-of-the-art performance on benchmark datasets. For volumetric data, \cite{hu2024diffunet} introduces diffusion-embedded 3D UNets, addressing memory constraints through adaptive spatiotemporal sampling. Test.
\end{multicols}
